## ShapeGen

This project generates a type of procedural 3D shapes (currently rectangular rings) and trains on the dataset and generates those shapes. 

Write-up: [PDF](https://drive.google.com/file/d/1yJft7YZPfo_rGE_y24le8Y3cd_PYv6xP/view?usp=sharing)

![Alt text](/interp.gif)

---

### Files

The following files are listed in model training order. 

**generate_data.py**: generate a dataset of procedural shapes (rectangular rings) using ```bpy``` in Blender

**preprocess.py**: voxelize the generated wavefront objects and save to .npy files

**./point_sampling**: create .hdf5 datasets using the .npy files

**./IMGAN**: autoencoder and generator network from IM-NET

**analysis.py**: Calculate the Chamfer distance and MSE between ground truth shapes and shapes generated by AE decoding Wasserstein GAN's latent codes. 

Note: IMNET's paper called the Wasserstein GAN a latent-GAN, but here I will use the proper name. 

---

### How to use this repo

- Prepare data as wavefront objects, then use **preprocess.py** to save them as numpy arrays. 

- Use **./point_sampling** to sample point-value pairs. **gather_hdf5.py**  --> **test_hdf5.py** --> **gather_vox_train_test.py** --> hdf5 training and testing set. 

    - [link to files]

- Move the datasets into **./IMGAN/data** and use the command below to train the autoencoder (```model.py```) for 15 epochs. Samples will be saved in **./IMGAN/samples**, the model weights will be saved in **./IMGAN/checkpoint**. Loss graph will be generated.

    - ```python main.py --ae --train --epoch 15 --real_size 16 --batch_size_input 4096```

- Use the command below and comment / uncomment corresponding lines in **./IMGAN/main.py** to 1. extract latent codes (saved in **./IMGAN/data**) 2. get interpolation samples 3. get testing samples 

    - ```python main.py --ae```

- Now train the WGAN (```modelz.py```). The model will use the extracted latent codes as input for the WGAN critic. The model weights will be saved in **./IMGAN/checkpoint**. Loss graph will be generated, and numpy arrays containing loss information will be saved in **./IMGAN**.

    - ```python main.py --train --epoch 15000```

- Now we can get some sample objects. The below command will use the latest implicit GAN checkpoint to generate latent codes. (If you wish to use an earlier checkpoint, you can revise ```load()``` in ```modelz.py``` to load any checkpoint). The latent codes will be saved to **./IMGAN/data**. Then, the codes will be fed into the implicit decoder in the autoencoder. Shapes will be saved in **./IMGAN/samples**, and vertices will be saved in **./gen_square_rings_vox_64**. If you wish to use an earlier autoencoder checkpoint, revise ```load()``` in ```model.py```. 

    - ```python main.py```

- All data mentioned above can be found here: [results](https://drive.google.com/file/d/1l_M81H4vNHzia3LDX7jiN2xfCODb1vm3/view?usp=sharing). Copy the file into the root directory. Run ```python analysis.py``` to analyze data quantitatively. 

Note: for the above steps, change directory paths when necessary. 

---

IMNET was developed with tensorflow v1.15 and CUDA 9.1, but I had CUDA 10.2 when developing this project. If you are in the same boat, here are some some extra dll libraries you will need: [dll](https://drive.google.com/file/d/1if5xDeXOAnl6VOQZzyFHFvODAep3Z9mQ/view?usp=sharing).

IMNET repo: [IMNET](https://github.com/czq142857/IM-NET)